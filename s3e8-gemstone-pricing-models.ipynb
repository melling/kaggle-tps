{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mmellinger66/s3e8-gemstone-pricing-models?scriptVersionId=121247046\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":" <div style=\"background-color:rgba(177, 156, 217, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">Playground Season 3: Episode 8 - Gemstone Pricing Models</h1>\n</div>\n\n## Problem Type\n\nRegression\n\n## Evaluation Metric\n\n$$RMSE = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y_i})^2}$$\n\n```python\nscore = metrics.mean_squared_error(yvalid, preds_valid, squared=False)\n```","metadata":{"papermill":{"duration":0.014816,"end_time":"2023-02-20T21:54:23.794699","exception":false,"start_time":"2023-02-20T21:54:23.779883","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(177, 156, 217, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">Import Libraries</h1>\n</div>","metadata":{"papermill":{"duration":0.014334,"end_time":"2023-02-20T21:54:23.822106","exception":false,"start_time":"2023-02-20T21:54:23.807772","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from typing import List, Set, Dict, Tuple, Optional\n\nimport os\nimport time\nfrom pathlib import Path\nimport glob\nimport gc\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn import impute\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn import linear_model\nfrom sklearn import svm\nfrom sklearn import cluster\nfrom sklearn import model_selection\nfrom sklearn import ensemble\nfrom sklearn import datasets\n\nimport xgboost as xgb\nimport catboost as cb\nimport lightgbm as lgb\n\nimport optuna\nfrom optuna.visualization import plot_optimization_history, plot_param_importances\n\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\n# Visualization Libraries\nimport matplotlib as mpl\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport missingno as msno\nfrom folium import Map\nfrom folium.plugins import HeatMap\nfrom IPython.display import display_html, display_markdown, display_latex\nfrom colorama import Fore, Style\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option(\"display.max_rows\", 999)\npd.set_option(\"display.precision\", 5)","metadata":{"_kg_hide-input":true,"papermill":{"duration":3.551938,"end_time":"2023-02-20T21:54:27.386821","exception":false,"start_time":"2023-02-20T21:54:23.834883","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:25.016052Z","iopub.execute_input":"2023-03-04T00:51:25.016876Z","iopub.status.idle":"2023-03-04T00:51:29.193097Z","shell.execute_reply.started":"2023-03-04T00:51:25.016768Z","shell.execute_reply":"2023-03-04T00:51:29.191986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(177, 156, 217, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">Configuration</h1>\n</div>","metadata":{"papermill":{"duration":0.020835,"end_time":"2023-02-20T21:54:27.429741","exception":false,"start_time":"2023-02-20T21:54:27.408906","status":"completed"},"tags":[]}},{"cell_type":"code","source":"TARGET=\"price\"\nID=\"id\"\n\n# Optuna\nobjective_direction = \"minimize\"  # minimize, maximize","metadata":{"papermill":{"duration":0.030284,"end_time":"2023-02-20T21:54:27.480946","exception":false,"start_time":"2023-02-20T21:54:27.450662","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:29.199294Z","iopub.execute_input":"2023-03-04T00:51:29.201626Z","iopub.status.idle":"2023-03-04T00:51:29.207639Z","shell.execute_reply.started":"2023-03-04T00:51:29.201586Z","shell.execute_reply":"2023-03-04T00:51:29.206735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    path:str = \"../input/playground-series-s3e8/\"\n    gpu:bool = True\n    optimize:bool = True\n    n_optuna_trials:int = 30 # 5, 10, 30\n    fast_render:bool = False\n    calc_probability:bool = False\n    debug:bool = False\n    seed:int = 42\n    N_ESTIMATORS:int = 100  # 100, 300, 1000, 2000, 5000, 15_000, 20_000 GBDT\n    GPU_N_ESTIMATORS:int = 2000 # Want models to run fast during dev\n    N_FOLDS:int = 5","metadata":{"papermill":{"duration":0.031421,"end_time":"2023-02-20T21:54:27.532769","exception":false,"start_time":"2023-02-20T21:54:27.501348","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:29.211812Z","iopub.execute_input":"2023-03-04T00:51:29.212438Z","iopub.status.idle":"2023-03-04T00:51:29.224527Z","shell.execute_reply.started":"2023-03-04T00:51:29.212399Z","shell.execute_reply":"2023-03-04T00:51:29.223546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class clr:\n    S = Style.BRIGHT + Fore.LIGHTRED_EX\n    E = Style.RESET_ALL","metadata":{"papermill":{"duration":0.030119,"end_time":"2023-02-20T21:54:27.583097","exception":false,"start_time":"2023-02-20T21:54:27.552978","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:29.227664Z","iopub.execute_input":"2023-03-04T00:51:29.228364Z","iopub.status.idle":"2023-03-04T00:51:29.2384Z","shell.execute_reply.started":"2023-03-04T00:51:29.22832Z","shell.execute_reply":"2023-03-04T00:51:29.237336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(177, 156, 217, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">Library</h1>\n</div>","metadata":{"papermill":{"duration":0.024559,"end_time":"2023-02-20T21:54:27.632417","exception":false,"start_time":"2023-02-20T21:54:27.607858","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def read_data(path: str, analyze:bool=True) -> (pd.DataFrame, pd.DataFrame, pd.DataFrame):\n    data_dir = Path(path)\n\n    train = pd.read_csv(data_dir / \"train.csv\")\n    test = pd.read_csv(data_dir / \"test.csv\")\n    submission_df = pd.read_csv(data_dir / \"sample_submission.csv\")\n\n    if analyze:\n        print(clr.S + \"=== Shape of Data ===\"+clr.E)\n        print(f\" train data: Rows={train.shape[0]}, Columns={train.shape[1]}\")\n        print(f\" test data : Rows={test.shape[0]}, Columns={test.shape[1]}\")\n\n        print(clr.S + \"\\n=== Train Data: First 5 Rows ===\\n\"+clr.E)\n        display(train.head())\n        print(f\"\\n{clr.S}=== Train Column Names ==={clr.E}\\n\")\n        display(train.columns)\n        print(f\"\\n{clr.S}=== Features/Explanatory Variables ==={clr.E}\\n\")\n        eval_features(train)\n        print(f\"\\n{clr.S}=== Skewness ==={clr.E}\\n\")\n        check_skew(train)\n    return train, test, submission_df\n\ndef create_submission(model_name: str, target, preds, seed:int=42, nfolds:int=5) -> pd.DataFrame:\n    sample_submission[target] = preds #.astype(int)\n\n    if len(model_name) > 0:\n        fname = f\"submission_{model_name}_k{nfolds}_s{seed}.csv\"\n    else:\n        fname = \"submission.csv\"\n\n    sample_submission.to_csv(fname, index=False)\n\n    return sample_submission\n\ndef show_classification_scores(ground_truth:List[int], yhat:List[int]) -> None:\n    accuracy = metrics.accuracy_score(ground_truth, yhat)\n    precision = metrics.precision_score(ground_truth, yhat)\n    recall = metrics.recall_score(ground_truth, yhat)\n    roc = metrics.roc_auc_score(ground_truth, yhat)\n    f1 = metrics.f1_score(ground_truth, yhat)\n\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"ROC: {roc:.4f}\")\n    print(f\"f1: {f1:.4f}\")\n    \n\ndef label_encoder(train:pd.DataFrame, test:pd.DataFrame, columns:List[str]) -> (pd.DataFrame, pd.DataFrame) :\n    for col in columns:\n        train[col] = train[col].astype(str)\n        test[col] = test[col].astype(str)\n        train[col] = preprocessing.LabelEncoder().fit_transform(train[col])\n        test[col] = preprocessing.LabelEncoder().fit_transform(test[col])\n    return train, test   \n\ndef create_strat_folds(df:pd.DataFrame, TARGET, n_folds:int=5, seed:int=42) -> pd.DataFrame:\n    print(f\"TARGET={TARGET}, n_folds={n_folds}, seed={seed}\")\n    df[\"fold\"] = -1\n\n    kf = model_selection.StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n    # kf = GroupKFold(n_splits=Config.N_FOLDS)\n    for fold, (train_idx, valid_idx) in enumerate(kf.split(df, df[TARGET])):\n        df.loc[valid_idx, \"fold\"] = fold\n\n    # df.to_csv(f\"train_fold{num_folds}.csv\", index=False)\n    return df\n\n\ndef create_folds(df:pd.DataFrame, n_folds:int=5, seed:int=42) -> pd.DataFrame:\n    print(f\"n_folds={n_folds}, seed={seed}\")\n    df[\"fold\"] = -1\n\n    kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n\n    for fold, (train_idx, valid_idx) in enumerate(kf.split(df)):\n        df.loc[valid_idx, \"fold\"] = fold\n\n    # df.to_csv(f\"train_fold{num_folds}.csv\", index=False)\n    return df\n\ndef show_fold_scores(scores: List[float]) -> (float, float):\n    cv_score = np.mean(scores)  # Used in filename\n    std_dev = np.std(scores)\n    print(\n        f\"Scores -> Adjusted: {np.mean(scores) - np.std(scores):.8f} , mean: {np.mean(scores):.8f}, std: {np.std(scores):.8f}\"\n    )\n    return cv_score, std_dev\n\n\ndef feature_distribution_types(df:pd.DataFrame, display:bool=True) -> (List[str], List[str]):\n    continuous_features = list(df.select_dtypes(include=['int64', 'float64', 'uint8']).columns)\n    categorical_features = list(df.select_dtypes(include=['object', 'bool']).columns)\n    if display:\n        print(f\"{clr.S}Continuous Features={continuous_features}{clr.E}\\n\")\n        print(f\"{clr.S}Categorical Features={categorical_features}{clr.E}\")\n    return continuous_features, categorical_features   \n\ndef show_cardinality(df:pd.DataFrame, features:List[str]) -> None:\n    print(\"=== Cardinality ===\")\n    print(df[features].nunique())\n\n## === Model Support ===    \n\nfrom scipy.stats import mode\n\n\ndef merge_test_predictions(final_test_predictions:List[float], calc_probability:bool=True) -> List[float]:\n\n    if calc_probability:\n        print(\"Mean\")\n        result = np.mean(np.column_stack(final_test_predictions), axis=1)\n    else:\n        print(\"Mode\")\n        mode_result = mode(np.column_stack(final_test_predictions), axis=1)\n        result = mode_result[0].ravel()\n\n    return result\n\ndef summary_statistics(X:pd.DataFrame, enhanced=True) -> None:\n    desc = X.describe()\n    if enhanced:\n        desc.loc[\"var\"] = X.var(numeric_only=True).tolist()\n        desc.loc[\"skew\"] = X.skew(numeric_only=True).tolist()\n        desc.loc[\"kurt\"] = X.kurtosis(numeric_only=True).tolist()\n\n    with pd.option_context(\"display.precision\", 2):\n        style = desc.transpose().style.background_gradient(\n            cmap=\"coolwarm\"\n        )  # .set_precision(4)\n    display(style)\n    \ndef show_missing_features(df:pd.DataFrame) -> None:\n    missing_vals = df.isna().sum().sort_values(ascending=False)\n    print(missing_vals[missing_vals > 0])\n\n\ndef show_duplicate_records(df:pd.DataFrame) -> None:\n    dups = df.duplicated()\n    print(dups.sum())\n\n\ndef eval_features(df:pd.DataFrame) -> (List[str], List[str], List[str]):\n    ## Separate Categorical and Numerical Features\n    categorical_features = list(\n        df.select_dtypes(include=[\"category\", \"object\"]).columns\n    )\n    continuous_features = list(df.select_dtypes(include=[\"number\"]).columns)\n\n    print(f\"{clr.S}Continuous features:{clr.E} {continuous_features}\")\n    print(f\"{clr.S}Categorical features:{clr.E} {categorical_features}\")\n    print(\"\\n --- Cardinality of Categorical Features ---\\n\")\n\n    for feature in categorical_features:\n        cardinality = df[feature].nunique()\n        if cardinality < 10:\n            print(f\"{clr.S}{feature}{clr.E}: cardinality={cardinality}, {df[feature].unique()}\")\n        else:\n            print(f\"{clr.S}{feature}{clr.E}: cardinality={cardinality}\")\n    all_features = categorical_features + continuous_features\n    return all_features, categorical_features, continuous_features\n\n\ndef show_feature_importance(feature_importance_lst:List[str]) -> None:\n    fis_df = pd.concat(feature_importance_lst, axis=1)\n\n    fis_df.sort_values(\"0_importance\", ascending=True).head(40).plot(\n        kind=\"barh\", figsize=(12, 12), title=\"Feature Importance Across Folds\"\n    )\n    plt.show()\n\n\ndef show_feature_target_crosstab(df:pd.DataFrame, feature_lst:List[str], target:str) -> None:\n    for feature in feature_lst:\n        print(f\"\\n=== {feature} vs {target} ===\\n\")\n        display(\n            pd.crosstab(df[feature], df[target], margins=True)\n        )  # display keeps bold formatting\n\n\ndef show_cardinality(df:pd.DataFrame, features:List[str]) -> None:\n    print(f\"{clr.S}=== Cardinality ==={clr.E}\")\n    print(df[features].nunique())\n\n\ndef show_unique_features(df:pd.DataFrame, features:List[str]) -> None:\n    for col in features:\n        print(col, sorted(df[col].dropna().unique()))\n\n\ndef feature_distribution_types(df:pd.DataFrame, display:bool=True) -> (List[str], List[str]):\n    continuous_features = list(\n        df.select_dtypes(include=[\"int64\", \"float64\", \"uint8\"]).columns\n    )\n    categorical_features = list(df.select_dtypes(include=[\"object\", \"bool\"]).columns)\n    if display:\n        print(f\"{clr.S}Continuous Features={clr.E}{continuous_features}\\n\")\n        print(f\"{clr.S}Categorical Features={clr.E}{categorical_features}\")\n    return continuous_features, categorical_features\n\n\ndef describe(X:pd.DataFrame) -> None:\n    \"\"\"Deprecated: Use summary_statistics()\"\"\"\n    desc = X.describe()\n    desc.loc['var'] = X.var(numeric_only=True).tolist()\n    desc.loc['skew'] = X.skew(numeric_only=True).tolist()\n    desc.loc['kurt'] = X.kurtosis(numeric_only=True).tolist()\n\n    with pd.option_context('display.precision', 2):\n        style = desc.transpose().style.background_gradient(cmap='coolwarm') #.set_precision(4)\n    display(style)\n  \n\ndef check_skew(df:pd.DataFrame) -> None:\n    skew = df.skew(skipna=True,numeric_only=True).sort_values(ascending=False)\n    print(skew)\n    \ndef gpu_ify_lgbm(lgbm_dict):\n    if Config.gpu:\n        lgbm_dict[\"device\"] = \"gpu\"\n        lgbm_dict[\"boosting_type\"] = \"gbdt\"\n        lgbm_dict[\"gpu_platform_id\"] = 0\n        lgbm_dict[\"gpu_device_id\"] = 0\n    return lgbm_dict\n\ndef gpu_ify_cb(params):\n    if Config.gpu:\n        params[\"task_type\"] = \"GPU\"\n    return params    \n","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.054959,"end_time":"2023-02-20T21:54:27.703285","exception":false,"start_time":"2023-02-20T21:54:27.648326","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:29.241508Z","iopub.execute_input":"2023-03-04T00:51:29.242211Z","iopub.status.idle":"2023-03-04T00:51:29.302615Z","shell.execute_reply.started":"2023-03-04T00:51:29.242174Z","shell.execute_reply":"2023-03-04T00:51:29.301667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(177, 156, 217, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">Optuna Hyperparameter Optimization Library</h1>\n</div>","metadata":{"papermill":{"duration":0.013145,"end_time":"2023-02-20T21:54:27.729372","exception":false,"start_time":"2023-02-20T21:54:27.716227","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def objective_xgb(trial, X_train, X_valid, y_train, y_valid):\n\n    xgb_params = {\n        #         \"objective\": trial.suggest_categorical(\"objective\", [\"multi:softmax\"]),\n        #         \"eval_metric\": \"mlogloss\",\n        #         \"objective\": \"multi:softmax\",\n#         \"eval_metric\": \"rmse\",  # auc, rmse, mae\n        \"eval_metric\": trial.suggest_categorical(\"eval_metric\", [\"rmse\", \"mae\"]),\n        \"objective\": trial.suggest_categorical(\"objective\", [\"reg:squarederror\"]), # \"reg:squarederror\",\n        #         \"enable_categorical\": trial.suggest_categorical(\"use_label_encoder\", [True]),\n        \"use_label_encoder\": trial.suggest_categorical(\"use_label_encoder\", [False]),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1000, 5000, 100),\n        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-2, 0.25),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1, step=0.01),\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1, step=0.01),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 20),  # 10\n        \"gamma\": trial.suggest_float(\"gamma\", 0, 100, step=0.1),\n        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\"]),\n        \"tree_method\": trial.suggest_categorical(\n            \"tree_method\", [\"gpu_hist\"]\n        ),  # hist, gpu_hist\n        \"predictor\": \"gpu_predictor\",\n        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100),\n        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100),\n        \"random_state\": trial.suggest_categorical(\"random_state\", [42]),\n        \"n_jobs\": trial.suggest_categorical(\"n_jobs\", [4]),\n        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 1e-1, 1e3),\n        # \"min_child_weight\": trial.suggest_categorical(\"min_child_weight\", [256]),\n    }\n\n    # Model loading and training\n    model = xgb.XGBRegressor(**xgb_params)\n    model.fit(\n        X_train,\n        y_train,\n        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n        early_stopping_rounds=5000,\n        verbose=0,\n    )\n\n    print(f\"Number of boosting rounds: {model.best_iteration}\")\n    #     oof = model.predict_proba(X_valid)[:, 1] # Probability\n    oof = model.predict(X_valid)  # Classification: 0,1\n\n    return metrics.mean_squared_error(y_valid, oof, squared=False)\n\n\ndef objective_lgbm(trial, X_train, X_valid, y_train, y_valid):\n\n    lgbm_params = {\n        \"objective\": trial.suggest_categorical(\"objective\", [\"mae\", \"rmse\"]),\n        #         \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [1_000]),\n        #         \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [5000]),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 700, 5000),\n        \"importance_type\": \"gain\",\n        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1, step=0.01),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 1000),\n        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.1, 1.0),\n        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.1, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 15),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 300),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1, step=0.01),\n        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-2, 0.25),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 100),\n        \"random_state\": trial.suggest_categorical(\"random_state\", [42]),\n        \"n_jobs\": trial.suggest_categorical(\"n_jobs\", [4]),\n        #         'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-1, 1e3),\n        # \"min_child_weight\": trial.suggest_categorical(\"min_child_weight\", [256]),\n    }\n\n    # Model loading and training\n    model = lgb.LGBMRegressor(**lgbm_params)\n    model.fit(\n        X_train,\n        y_train,\n        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n        eval_metric=\"mae\",\n        callbacks=[\n            lgb.log_evaluation(500),\n            lgb.early_stopping(500, False, True),\n        ],\n    )\n\n    #     print(f\"Number of boosting rounds: {model.best_iteration}\")\n    oof = model.predict(X_valid)\n\n    return metrics.mean_squared_error(y_valid, oof, squared=False)\n#     return metrics.mean_absolute_error(y_valid, oof)\n\n\ndef objective_clf_lgbm(trial, X_train, X_valid, y_train, y_valid):\n\n    params = {\n        \"boosting_type\": \"gbdt\",\n        # \"objective\": trial.suggest_categorical(\"objective\", [\"mae\", \"rmse\"]),\n        #         \"objective\": trial.suggest_categorical(\"objective\", [\"multi:softprob\"]),\n        #         \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [1_000]),\n        #         \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [5000]),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 700, 1000),\n        \"importance_type\": \"gain\",\n        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-8, 10.0),\n        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-8, 10.0),\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1, step=0.01),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 1000),\n        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.1, 1.0),\n        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.1, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 15),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 1, 300),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1, step=0.01),\n        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-2, 0.25),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 100),\n        \"random_state\": trial.suggest_categorical(\"random_state\", [42]),\n        \"n_jobs\": trial.suggest_categorical(\"n_jobs\", [4]),\n        #         'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-1, 1e3),\n        # \"min_child_weight\": trial.suggest_categorical(\"min_child_weight\", [256]),\n    }\n    if Config.gpu:\n        params[\"device_type\"] = \"gpu\"\n\n    # Model loading and training\n    model = lgb.LGBMClassifier(**params)\n    model.fit(\n        X_train,\n        y_train,\n        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n        # eval_metric=\"mae\",\n        callbacks=[\n            lgb.log_evaluation(500),\n            lgb.early_stopping(500, False, True),\n        ],\n    )\n\n    #     print(f\"Number of boosting rounds: {model.best_iteration}\")\n    oof = model.predict(X_valid)\n\n    #     return accuracy_score(y_valid, oof)\n    return metrics.roc_auc_score(y_valid, oof)\n\n\ndef objective_cb(trial, X_train, X_valid, y_train, y_valid):\n\n    cb_params = {\n        \"iterations\": 100,\n        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.1, 1.0),\n        \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1, 100),\n        \"bagging_temperature\": trial.suggest_loguniform(\n            \"bagging_temperature\", 0.1, 20.0\n        ),\n        \"random_strength\": trial.suggest_float(\"random_strength\", 1.0, 2.0),\n        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 300),\n          \"use_best_model\": True,\n#         \"task_type\": \"GPU\",\n        \"random_seed\": 42,\n    }\n\n    # Model loading and training\n    model = cb.CatBoostRegressor(**cb_params)\n\n    model.fit(\n        X_train,\n        y_train,\n        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n        # eval_metric=\"accuracy\",\n        early_stopping_rounds=500,\n        verbose=False,\n    )\n\n#     print(f\"Number of boosting rounds: {model.best_iteration}\")\n    # oof = model.predict_proba(X_valid)[:, 1]\n    oof = model.predict(X_valid)  # Classification\n    return metrics.mean_squared_error(y_valid, oof, squared=False)\n#     return metrics.mean_absolute_error(y_valid, oof)\n# \n#     return accuracy_score(y_valid, oof)\n\ndef objective_clf_cb(trial, X_train, X_valid, y_train, y_valid):\n\n    cb_params = {\n        \"iterations\": 10,  # 1000\n        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.1, 1.0),\n        \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1, 100),\n        \"bagging_temperature\": trial.suggest_loguniform(\n            \"bagging_temperature\", 0.1, 20.0\n        ),\n        \"random_strength\": trial.suggest_float(\"random_strength\", 1.0, 2.0),\n        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 300),\n        \"use_best_model\": True,\n#             \"task_type\": \"GPU\",\n        \"random_seed\": 42,\n    }\n\n    # Model loading and training\n    model = cb.CatBoostClassifier(**cb_params)\n    model.fit(\n        X_train,\n        y_train,\n        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n        # eval_metric=\"accuracy\",\n        early_stopping_rounds=500,\n        verbose=False,\n    )\n\n    # print(f\"Number of boosting rounds: {model.best_iteration}\")\n    # oof = model.predict_proba(X_valid)[:, 1]\n    oof = model.predict(X_valid)  # Classification\n\n    return metrics.accuracy_score(y_valid, oof)","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.044484,"end_time":"2023-02-20T21:54:27.786696","exception":false,"start_time":"2023-02-20T21:54:27.742212","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:29.307084Z","iopub.execute_input":"2023-03-04T00:51:29.309452Z","iopub.status.idle":"2023-03-04T00:51:29.351766Z","shell.execute_reply.started":"2023-03-04T00:51:29.309415Z","shell.execute_reply":"2023-03-04T00:51:29.35065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(177, 156, 217, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">Load Train/Test Data and Analyze</h1>\n</div>\n\n## Load the following files\n\n - train.csv - Data used to build our machine learning model\n - test.csv - Data used to build our machine learning model. Does not contain the target variable\n - sample_submission.csv - A file in the proper format to submit test predictions","metadata":{"papermill":{"duration":0.012559,"end_time":"2023-02-20T21:54:27.812533","exception":false,"start_time":"2023-02-20T21:54:27.799974","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\ntrain, test, sample_submission = read_data(Config.path, analyze=True)                                ","metadata":{"papermill":{"duration":0.162289,"end_time":"2023-02-20T21:54:27.987603","exception":false,"start_time":"2023-02-20T21:54:27.825314","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:29.35609Z","iopub.execute_input":"2023-03-04T00:51:29.358413Z","iopub.status.idle":"2023-03-04T00:51:30.315674Z","shell.execute_reply.started":"2023-03-04T00:51:29.358377Z","shell.execute_reply":"2023-03-04T00:51:30.314541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"papermill":{"duration":0.03226,"end_time":"2023-02-20T21:54:28.034157","exception":false,"start_time":"2023-02-20T21:54:28.001897","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:30.325881Z","iopub.execute_input":"2023-03-04T00:51:30.326257Z","iopub.status.idle":"2023-03-04T00:51:30.365676Z","shell.execute_reply.started":"2023-03-04T00:51:30.326222Z","shell.execute_reply":"2023-03-04T00:51:30.364317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original = pd.read_csv(\"../input/gemstone-price-prediction/cubic_zirconia.csv\", index_col=[0])\noriginal = original[-original.depth.isna()]\noriginal.head()","metadata":{"papermill":{"duration":0.057436,"end_time":"2023-02-20T21:54:28.105399","exception":false,"start_time":"2023-02-20T21:54:28.047963","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:30.369632Z","iopub.execute_input":"2023-03-04T00:51:30.369979Z","iopub.status.idle":"2023-03-04T00:51:30.494641Z","shell.execute_reply.started":"2023-03-04T00:51:30.369948Z","shell.execute_reply":"2023-03-04T00:51:30.493339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-04T00:51:30.500063Z","iopub.execute_input":"2023-03-04T00:51:30.500531Z","iopub.status.idle":"2023-03-04T00:51:30.516356Z","shell.execute_reply.started":"2023-03-04T00:51:30.50046Z","shell.execute_reply":"2023-03-04T00:51:30.514617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['is_original']    = 0\ntest['is_original']     = 0\noriginal['is_original'] = 1\ncombined = pd.concat([train, original], ignore_index=True).drop_duplicates()\ntrain = combined","metadata":{"papermill":{"duration":0.02745,"end_time":"2023-02-20T21:54:28.204655","exception":false,"start_time":"2023-02-20T21:54:28.177205","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:30.529399Z","iopub.execute_input":"2023-03-04T00:51:30.530195Z","iopub.status.idle":"2023-03-04T00:51:30.774592Z","shell.execute_reply.started":"2023-03-04T00:51:30.530157Z","shell.execute_reply":"2023-03-04T00:51:30.773506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined.head()","metadata":{"papermill":{"duration":0.031655,"end_time":"2023-02-20T21:54:28.251715","exception":false,"start_time":"2023-02-20T21:54:28.22006","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:30.776257Z","iopub.execute_input":"2023-03-04T00:51:30.77663Z","iopub.status.idle":"2023-03-04T00:51:30.80147Z","shell.execute_reply.started":"2023-03-04T00:51:30.776592Z","shell.execute_reply":"2023-03-04T00:51:30.800579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary_statistics(train.drop(columns=[ID], axis=1), enhanced=True)","metadata":{"papermill":{"duration":0.176237,"end_time":"2023-02-20T21:54:28.442893","exception":false,"start_time":"2023-02-20T21:54:28.266656","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:30.80456Z","iopub.execute_input":"2023-03-04T00:51:30.808068Z","iopub.status.idle":"2023-03-04T00:51:31.163236Z","shell.execute_reply.started":"2023-03-04T00:51:30.808026Z","shell.execute_reply":"2023-03-04T00:51:31.162125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Outlier Detection","metadata":{"papermill":{"duration":0.014688,"end_time":"2023-02-20T21:54:28.472831","exception":false,"start_time":"2023-02-20T21:54:28.458143","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# https://www.kaggle.com/code/lyasdemir/best-algorithm-for-prediction-xgboost\n    \ndef iqr(data:pd.DataFrame, var:str):# outliers detecion .\n    q1 = np.quantile(data[var], 0.25)\n    q3 = np.quantile(data[var], 0.75)\n    diff = q3 - q1\n    lower_t = q1 - (1.5 * diff)\n    upper_t = q3 + (1.5 * diff)\n    return data[(data[var] < lower_t) | (data[var] > upper_t)]\n\n# iqr(train, \"squareMeters\")","metadata":{"papermill":{"duration":0.024195,"end_time":"2023-02-20T21:54:28.511801","exception":false,"start_time":"2023-02-20T21:54:28.487606","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:31.167639Z","iopub.execute_input":"2023-03-04T00:51:31.16805Z","iopub.status.idle":"2023-03-04T00:51:31.177747Z","shell.execute_reply.started":"2023-03-04T00:51:31.16801Z","shell.execute_reply":"2023-03-04T00:51:31.176005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/code/sujithmandala/playground-s3-e8-ensemble-model-98-accuracy\n\ndef detect_outliers(data:pd.DataFrame) -> pd.DataFrame:\n    outlier_percents = {}\n    for column in data.columns:\n        if data[column].dtype != object:\n            q1 = np.quantile(data[column], 0.25)\n            q3 = np.quantile(data[column], 0.75)\n            iqr = q3 - q1\n            upper_bound = q3 + (1.5 * iqr)\n            lower_bound = q1 - (1.5 * iqr)\n            outliers = data[(data[column] > upper_bound) | (data[column] < lower_bound)][column]\n            outlier_percentage = len(outliers) / len(data[column]) * 100\n            outlier_percents[column] = outlier_percentage\n            outlier_dataframe = pd.DataFrame(data = outlier_percents.values() ,index=outlier_percents.keys() ,columns=['Outlier_percentage'])\n    \n    return outlier_dataframe.sort_values(by = 'Outlier_percentage', ascending = False)\n\ndetect_outliers(train)\n","metadata":{"papermill":{"duration":0.033761,"end_time":"2023-02-20T21:54:28.560668","exception":false,"start_time":"2023-02-20T21:54:28.526907","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:31.179246Z","iopub.execute_input":"2023-03-04T00:51:31.179889Z","iopub.status.idle":"2023-03-04T00:51:31.27288Z","shell.execute_reply.started":"2023-03-04T00:51:31.179837Z","shell.execute_reply":"2023-03-04T00:51:31.271846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/code/sujithmandala/playground-s3-e8-ensemble-model-98-accuracy\n    \ndef detect_outliers(data:pd.DataFrame) -> pd.DataFrame:\n    outlier_percents = {}\n    for column in data.columns:\n        if data[column].dtype != object:\n            q1 = np.quantile(data[column], 0.25)\n            q3 = np.quantile(data[column], 0.75)\n            iqr = q3 - q1\n            upper_bound = q3 + (1.5 * iqr)\n            lower_bound = q1 - (1.5 * iqr)\n            outliers = data[(data[column] > upper_bound) | (data[column] < lower_bound)][column]\n            outlier_percentage = len(outliers) / len(data[column]) * 100\n            outlier_percents[column] = outlier_percentage\n            outlier_dataframe = pd.DataFrame(data = outlier_percents.values() ,index=outlier_percents.keys() ,columns=['Outlier_percentage'])\n    \n    return outlier_dataframe.sort_values(by = 'Outlier_percentage', ascending = False)\n\ndetect_outliers(test)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-04T00:51:31.274722Z","iopub.execute_input":"2023-03-04T00:51:31.275425Z","iopub.status.idle":"2023-03-04T00:51:31.335154Z","shell.execute_reply.started":"2023-03-04T00:51:31.275387Z","shell.execute_reply":"2023-03-04T00:51:31.334201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# iqr(train,\"floors\")","metadata":{"papermill":{"duration":0.032026,"end_time":"2023-02-20T21:54:28.607877","exception":false,"start_time":"2023-02-20T21:54:28.575851","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:31.336648Z","iopub.execute_input":"2023-03-04T00:51:31.337427Z","iopub.status.idle":"2023-03-04T00:51:31.343562Z","shell.execute_reply.started":"2023-03-04T00:51:31.337389Z","shell.execute_reply":"2023-03-04T00:51:31.342022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(177, 156, 217, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">Feature Engineering</h1>\n</div>","metadata":{"papermill":{"duration":0.015441,"end_time":"2023-02-20T21:54:28.638699","exception":false,"start_time":"2023-02-20T21:54:28.623258","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Categorical/Numerical Variables","metadata":{"papermill":{"duration":0.015462,"end_time":"2023-02-20T21:54:28.669213","exception":false,"start_time":"2023-02-20T21:54:28.653751","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# train.drop(['cityCode'], axis=1, inplace=True)\n# test.drop(['cityCode'], axis=1, inplace=True)","metadata":{"papermill":{"duration":0.028453,"end_time":"2023-02-20T21:54:28.712716","exception":false,"start_time":"2023-02-20T21:54:28.684263","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:31.345812Z","iopub.execute_input":"2023-03-04T00:51:31.346209Z","iopub.status.idle":"2023-03-04T00:51:31.353097Z","shell.execute_reply.started":"2023-03-04T00:51:31.346173Z","shell.execute_reply":"2023-03-04T00:51:31.351719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handle Outliers\n- https://www.kaggle.com/code/lyasdemir/best-algorithm-for-prediction-xgboost\n- https://www.kaggle.com/code/mnokno/paris-housing-price-prediction-using-xgboost","metadata":{"papermill":{"duration":0.015179,"end_time":"2023-02-20T21:54:28.742894","exception":false,"start_time":"2023-02-20T21:54:28.727715","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# features_with_outliers = ['attic', 'garage', 'made', 'basement', 'floors', 'cityCode', 'squareMeters']\n# features_with_outliers = ['attic', 'garage', 'made', 'basement', 'floors',  'squareMeters']","metadata":{"papermill":{"duration":0.022573,"end_time":"2023-02-20T21:54:28.780421","exception":false,"start_time":"2023-02-20T21:54:28.757848","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:31.356069Z","iopub.execute_input":"2023-03-04T00:51:31.356509Z","iopub.status.idle":"2023-03-04T00:51:31.363557Z","shell.execute_reply.started":"2023-03-04T00:51:31.356474Z","shell.execute_reply":"2023-03-04T00:51:31.361536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/code/mnokno/paris-housing-price-prediction-using-xgboost\n\ndef remove_outliers(df:pd.DataFrame) -> pd.DataFrame:\n    for c in features_with_outliers:\n        if c == 'garage':\n            first_percentile = df[c].quantile(0.001)\n            df = df[df[c] > first_percentile]\n\n        ninety_ninth_percentile = df[c].quantile(0.999)\n        df = df[df[c] < ninety_ninth_percentile]\n        #df_t = df_t[(df_t[c] > first_percentile) & (df_t[c] < ninety_ninth_percentile)]\n    return df\n","metadata":{"papermill":{"duration":0.025478,"end_time":"2023-02-20T21:54:28.821132","exception":false,"start_time":"2023-02-20T21:54:28.795654","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:31.365606Z","iopub.execute_input":"2023-03-04T00:51:31.365932Z","iopub.status.idle":"2023-03-04T00:51:31.372933Z","shell.execute_reply.started":"2023-03-04T00:51:31.365881Z","shell.execute_reply":"2023-03-04T00:51:31.372021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(f'Before: {len(train)}')\n# train = remove_outliers(train)\n# print(f'After: {len(train)}')","metadata":{"papermill":{"duration":0.052277,"end_time":"2023-02-20T21:54:28.888247","exception":false,"start_time":"2023-02-20T21:54:28.83597","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:31.374526Z","iopub.execute_input":"2023-03-04T00:51:31.375228Z","iopub.status.idle":"2023-03-04T00:51:31.383278Z","shell.execute_reply.started":"2023-03-04T00:51:31.375195Z","shell.execute_reply":"2023-03-04T00:51:31.381968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"papermill":{"duration":0.034316,"end_time":"2023-02-20T21:54:28.96875","exception":false,"start_time":"2023-02-20T21:54:28.934434","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:31.385079Z","iopub.execute_input":"2023-03-04T00:51:31.386284Z","iopub.status.idle":"2023-03-04T00:51:31.413391Z","shell.execute_reply.started":"2023-03-04T00:51:31.38625Z","shell.execute_reply":"2023-03-04T00:51:31.41195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.reset_index(drop=True).copy()\ntrain.head(10)","metadata":{"papermill":{"duration":0.03648,"end_time":"2023-02-20T21:54:29.020687","exception":false,"start_time":"2023-02-20T21:54:28.984207","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:31.415066Z","iopub.execute_input":"2023-03-04T00:51:31.415663Z","iopub.status.idle":"2023-03-04T00:51:31.468392Z","shell.execute_reply.started":"2023-03-04T00:51:31.41563Z","shell.execute_reply":"2023-03-04T00:51:31.46742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"excluded_features = [TARGET, ID, \"fold\"]","metadata":{"papermill":{"duration":0.023718,"end_time":"2023-02-20T21:54:29.148537","exception":false,"start_time":"2023-02-20T21:54:29.124819","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:31.46978Z","iopub.execute_input":"2023-03-04T00:51:31.470191Z","iopub.status.idle":"2023-03-04T00:51:31.478068Z","shell.execute_reply.started":"2023-03-04T00:51:31.470154Z","shell.execute_reply":"2023-03-04T00:51:31.476938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cont_features, cat_features = feature_distribution_types(train, display=True)\nshow_cardinality(train, cat_features)\n\ncont_features = [feature for feature in cont_features if feature not in excluded_features]\ncat_features = [feature for feature in cat_features if feature not in excluded_features]\n\nFEATURES = cont_features + cat_features\nFEATURES","metadata":{"papermill":{"duration":0.033127,"end_time":"2023-02-20T21:54:29.197652","exception":false,"start_time":"2023-02-20T21:54:29.164525","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:31.479549Z","iopub.execute_input":"2023-03-04T00:51:31.481243Z","iopub.status.idle":"2023-03-04T00:51:31.55522Z","shell.execute_reply.started":"2023-03-04T00:51:31.481209Z","shell.execute_reply":"2023-03-04T00:51:31.554273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train, test = label_encoder(train, test, cat_features)\ntrain = pd.get_dummies(train,columns=['cut','color','clarity']) # Will remove original feature names\ntest = pd.get_dummies(test,columns=['cut','color','clarity'])","metadata":{"execution":{"iopub.status.busy":"2023-03-04T00:51:31.556462Z","iopub.execute_input":"2023-03-04T00:51:31.5574Z","iopub.status.idle":"2023-03-04T00:51:31.700098Z","shell.execute_reply.started":"2023-03-04T00:51:31.557365Z","shell.execute_reply":"2023-03-04T00:51:31.698918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-04T00:51:31.701374Z","iopub.execute_input":"2023-03-04T00:51:31.701948Z","iopub.status.idle":"2023-03-04T00:51:31.729653Z","shell.execute_reply.started":"2023-03-04T00:51:31.701884Z","shell.execute_reply":"2023-03-04T00:51:31.728837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cont_features, cat_features = feature_distribution_types(train, display=True)\nshow_cardinality(train, cat_features)\n\ncont_features = [feature for feature in cont_features if feature not in excluded_features]\ncat_features = [feature for feature in cat_features if feature not in excluded_features]\n\nFEATURES = cont_features + cat_features\nFEATURES","metadata":{"execution":{"iopub.status.busy":"2023-03-04T00:51:31.730755Z","iopub.execute_input":"2023-03-04T00:51:31.731263Z","iopub.status.idle":"2023-03-04T00:51:31.755684Z","shell.execute_reply.started":"2023-03-04T00:51:31.73123Z","shell.execute_reply":"2023-03-04T00:51:31.754713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(177, 156, 217, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">Optuna Hyperparameter Optimization</h1>\n</div>","metadata":{"papermill":{"duration":0.015936,"end_time":"2023-02-20T21:54:29.23021","exception":false,"start_time":"2023-02-20T21:54:29.214274","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\n\nif Config.optimize:\n    y = train[TARGET]\n    X = train[FEATURES].copy()\n\n    X_test = test[FEATURES].copy()\n    X_train, X_valid, y_train, y_valid = model_selection.train_test_split(\n        X, y, test_size=0.2, random_state=Config.seed\n    )\n\n# === XGB ===\n\ntime_limit = 3600 * 3\nbest_xgb_params = {}\n\nif Config.optimize:\n    study = optuna.create_study(direction=objective_direction)\n    study.optimize(\n        lambda trial: objective_xgb(trial, X_train, X_valid, y_train, y_valid),\n        n_trials=Config.n_optuna_trials,\n        # timeout=time_limit,  # this or n_trials\n    )\n\nif Config.optimize:\n    print(\"Number of finished trials:\", len(study.trials))\n    print(\"Best XGB trial parameters:\", study.best_trial.params)\n    print(\"Best score:\", study.best_value)\n    best_xgb_params = study.best_trial.params\n\n## === LGBM ===\n\ntime_limit = 3600 * 3\nbest_lgbm_params = {}\n\nif Config.optimize:\n    study = optuna.create_study(direction=objective_direction) # minimize, maximize\n    study.optimize(\n        lambda trial: objective_lgbm(trial, X_train, X_valid, y_train, y_valid),\n        n_trials=Config.n_optuna_trials,\n        # timeout=time_limit,  # this or n_trials\n    )\n\nif Config.optimize:\n    print(\"Number of finished trials:\", len(study.trials))\n    print(\"Best LGBM trial parameters:\", study.best_trial.params)\n    print(\"Best score:\", study.best_value)\n    best_lgbm_params = study.best_trial.params\n\n## === CatBoost\n\ntime_limit = 3600 * 3\n# best_cb_params = {}\nbest_cb_params = {'learning_rate': 0.45743264601999495,\n                  'l2_leaf_reg': 41.338946049390074,\n                  'bagging_temperature': 0.3472567739474319,\n                  'random_strength': 1.7332249677756242, \n                  'depth': 1,\n                  'min_data_in_leaf': 6}\n\nif Config.optimize:\n    study = optuna.create_study(direction=objective_direction) # minimize, maximize\n    study.optimize(\n        lambda trial: objective_cb(trial, X_train, X_valid, y_train, y_valid),\n        n_trials=Config.n_optuna_trials,\n        # timeout=time_limit,  # this or n_trials\n    )\n\nif Config.optimize:\n    print(\"Number of finished trials:\", len(study.trials))\n    print(\"Best Cat trial parameters:\", study.best_trial.params)\n    print(\"Best score:\", study.best_value)\n    best_cb_params = study.best_trial.params","metadata":{"papermill":{"duration":0.031366,"end_time":"2023-02-20T21:54:29.277831","exception":false,"start_time":"2023-02-20T21:54:29.246465","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:51:31.757444Z","iopub.execute_input":"2023-03-04T00:51:31.758186Z","iopub.status.idle":"2023-03-04T00:57:02.968505Z","shell.execute_reply.started":"2023-03-04T00:51:31.758149Z","shell.execute_reply":"2023-03-04T00:57:02.96748Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(177, 156, 217, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">Train Models with Cross Validation</h1>\n</div>","metadata":{"papermill":{"duration":0.015947,"end_time":"2023-02-20T21:54:29.310426","exception":false,"start_time":"2023-02-20T21:54:29.294479","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train = create_folds(train, Config.N_FOLDS)\n# train = create_strat_folds(train, TARGET, Config.N_FOLDS)","metadata":{"papermill":{"duration":0.035386,"end_time":"2023-02-20T21:54:29.362094","exception":false,"start_time":"2023-02-20T21:54:29.326708","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:57:02.969814Z","iopub.execute_input":"2023-03-04T00:57:02.970209Z","iopub.status.idle":"2023-03-04T00:57:03.010911Z","shell.execute_reply.started":"2023-03-04T00:57:02.970171Z","shell.execute_reply":"2023-03-04T00:57:03.009811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_cv_scores = pd.DataFrame(\n    {\n        \"Model\": pd.Series(dtype=\"str\"),\n        \"Score\": pd.Series(dtype=\"float\"),\n        \"StdDev\": pd.Series(dtype=\"float\"),\n        \"RunTime\": pd.Series(dtype=\"float\"),\n    }\n)\n\noof = train[[ID, TARGET, \"fold\"]].copy().reset_index(drop=True).copy()\noof.set_index(ID, inplace=True)\noof.head()","metadata":{"papermill":{"duration":0.03886,"end_time":"2023-02-20T21:54:29.41885","exception":false,"start_time":"2023-02-20T21:54:29.37999","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:57:03.012368Z","iopub.execute_input":"2023-03-04T00:57:03.01298Z","iopub.status.idle":"2023-03-04T00:57:03.033812Z","shell.execute_reply.started":"2023-03-04T00:57:03.012939Z","shell.execute_reply":"2023-03-04T00:57:03.032935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_tree_model_fi(model, features:List[str]) -> None:\n    print(\"\\n=== Model Feature Importance ===\")\n    for i in model.feature_importances_.argsort()[::-1]:\n        print(features[i], model.feature_importances_[i]/model.feature_importances_.sum())\n\ndef save_oof_predictions(model_name:str, final_valid_predictions, oof:pd.DataFrame) -> pd.DataFrame:\n    final_valid_predictions_df = process_valid_predictions(\n        final_valid_predictions, ID, model_name\n    )\n    display(final_valid_predictions_df.head())\n    oof[f\"pred_{model_name}\"] = final_valid_predictions_df[f\"pred_{model_name}\"]\n\n    return oof\n\ndef save_test_predictions(model_name:str, final_test_predictions, submission_df:pd.DataFrame, result_field:str=TARGET) -> None:\n    result = merge_test_predictions(final_test_predictions, Config.calc_probability)\n    # result[:20]\n    submission_df[f\"target_{model_name}\"] = result #.astype(int)\n    #     submission_df.head(10)\n    ss = submission_df[[ID, f\"target_{model_name}\"]].copy().reset_index(drop=True)\n    ss.rename(columns={f\"target_{model_name}\": result_field}, inplace=True)\n    ss.to_csv(\n        f\"submission_{model_name}.csv\", index=False\n    )  # Can submit the individual model\n    print(\"=== Target Value Counts ===\")\n#     display(ss[TARGET].value_counts())\n    ss.head(10)\n\ndef process_valid_predictions(final_valid_predictions, train_id, model_name:str) -> pd.DataFrame:\n    model = f\"pred_{model_name}\"\n    final_valid_predictions_df = pd.DataFrame.from_dict(\n        final_valid_predictions, orient=\"index\"\n    ).reset_index()\n    final_valid_predictions_df.columns = [train_id, model]\n    final_valid_predictions_df.set_index(train_id, inplace=True)\n    final_valid_predictions_df.sort_index(inplace=True)\n    final_valid_predictions_df.to_csv(f\"train_pred_{model_name}.csv\", index=True)\n\n    return final_valid_predictions_df\n\ndef add_score(score_df:pd.DataFrame, model_name:str, score:float, std:float):\n    dict1 = {\"Model\": model_name, \"Score\": cv_score, \"StdDev\": std_dev}\n    score_df = score_df.append(dict1, ignore_index=True)\n    return score_df","metadata":{"papermill":{"duration":0.03047,"end_time":"2023-02-20T21:54:29.466299","exception":false,"start_time":"2023-02-20T21:54:29.435829","status":"completed"},"tags":[],"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-03-04T00:57:03.040774Z","iopub.execute_input":"2023-03-04T00:57:03.041055Z","iopub.status.idle":"2023-03-04T00:57:03.052173Z","shell.execute_reply.started":"2023-03-04T00:57:03.04103Z","shell.execute_reply":"2023-03-04T00:57:03.051195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_cv_model(\n    df:pd.DataFrame,\n    test:pd.DataFrame,\n    get_model_fn,\n    FEATURES:List[str],\n    TARGET:str,\n    calc_probability:bool,\n    rowid,\n    params,\n    n_folds:int=5,\n    seed:int=42,\n):\n\n    final_test_predictions = []\n    final_valid_predictions = {}\n    fold_scores = []  # Scores of Validation Set\n    feature_importance_lst = []\n\n    test = test[FEATURES].copy()\n\n    for fold in range(n_folds):\n        print(10 * \"=\", f\"Fold {fold+1}/{n_folds}\", 10 * \"=\")\n\n        start_time = time.time()\n\n        xtrain = df[df.fold != fold].reset_index(\n            drop=True\n        )  # Everything not in validation fold\n        xvalid = df[df.fold == fold].reset_index(drop=True)\n        xtest = test.copy()\n\n        valid_ids = xvalid.id.values.tolist()  # Id's of everything in validation fold\n\n        ytrain = xtrain[TARGET]\n        yvalid = xvalid[TARGET]\n\n        xtrain = xtrain[FEATURES]\n        xvalid = xvalid[FEATURES]\n\n        scaler = preprocessing.StandardScaler()\n#         scaler = preprocessing.MinMaxScaler()\n        xtrain = scaler.fit(xtrain).transform(xtrain)\n        xvalid = scaler.transform(xvalid)\n        xtest = scaler.transform(xtest)\n\n        model = get_model_fn # ()\n\n        model.fit(\n            xtrain,\n            ytrain,\n        )\n        if calc_probability:\n            preds_valid = model.predict_proba(xvalid)[:, 1]\n            test_preds = model.predict_proba(xtest)[:, 1]\n        else:\n            preds_valid = model.predict(xvalid)\n            test_preds = model.predict(xtest)\n\n        preds_valid_class = model.predict(xvalid)\n        \n        final_test_predictions.append(test_preds)\n        final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n\n#         fold_score = metrics.accuracy_score(yvalid, preds_valid_class)  # Validation Set Score\n        fold_score = metrics.mean_absolute_error(\n            yvalid, preds_valid\n        ) \n#         fold_score = metrics.roc_auc_score(yvalid.values, preds_valid)  # Validation Set Score\n#         show_classification_scores(yvalid.values, preds_valid_class)\n\n#         fold_score = metrics.roc_auc_score(yvalid, preds_valid)  # Validation Set Score\n#         fold_score = metrics.mean_squared_error(yvalid, preds_valid, squared=False)\n        fold_scores.append(fold_score)\n        #         importance_list.append(model.coef_.ravel())\n\n        fi = []\n        # Feature importance\n#         fi = pd.DataFrame(\n#             index=FEATURES,\n#             data=model.coef_.ravel(),\n#             columns=[f\"{fold}_importance\"],\n#         )\n        \n        feature_importance_lst.append(fi)\n\n        run_time = time.time() - start_time\n\n        print(f\"fold: {fold+1}, Score: {fold_score}, Run Time: {run_time:.2f}\")\n\n    return (\n        model,\n        feature_importance_lst,\n        fold_scores,\n        final_valid_predictions,\n        final_test_predictions,\n    )\n\n\ndef train_xgb_model(\n    df:pd.DataFrame,\n    test:pd.DataFrame,\n    get_model_fn,\n    FEATURES:List[str],\n    TARGET:str,\n    calc_probability:bool,\n    rowid:str,\n    params,\n    n_folds:int=5,\n    seed:int=42,\n):\n\n    print(params)\n    final_test_predictions = []\n    final_valid_predictions = {}\n    fold_scores = []  # Scores of Validation Set\n    feature_importance_lst = []\n\n    test = test[FEATURES].copy()\n\n    for fold in range(n_folds):\n        print(10 * \"=\", f\"Fold {fold+1}/{n_folds}\", 10 * \"=\")\n\n        start_time = time.time()\n\n        xtrain = df[df.fold != fold].reset_index(\n            drop=True\n        )  # Everything not in validation fold\n        xvalid = df[df.fold == fold].reset_index(drop=True)\n        xtest = test.copy()\n\n        valid_ids = xvalid.id.values.tolist()  # Id's of everything in validation fold\n\n        ytrain = xtrain[TARGET]\n        yvalid = xvalid[TARGET]\n\n        xtrain = xtrain[FEATURES]\n        xvalid = xvalid[FEATURES]\n\n        model = get_model_fn # (params)\n\n        model.fit(\n            xtrain,\n            ytrain,\n            eval_set=[(xvalid, yvalid)],\n            #             eval_metric=\"acc\",  # auc\n            verbose=0,\n            #             early_stopping_rounds=3000,\n            #             callbacks=[\n            #                 xgb.log_evaluation(0),\n            #                 xgb.early_stopping(500, False, True),\n            #             ],\n        )\n\n        if calc_probability:\n            preds_valid = model.predict_proba(xvalid)[:, 1]\n            test_preds = model.predict_proba(xtest)[:, 1]\n        else:\n            preds_valid = model.predict(xvalid)\n            test_preds = model.predict(xtest)\n\n        preds_valid_class = model.predict(xvalid)\n        \n        final_test_predictions.append(test_preds)\n        if Config.debug:\n            print(f\"GT Type: {type(yvalid.values)}\")\n            print(f\"Preds Type: {type(preds_valid_class)}\")\n            print(f\"         GT:{yvalid.values[:20]}\")\n            print(f\"Preds Class:{preds_valid_class[:20]}\")\n            print(f\"Preds Prob:{preds_valid[:20]}\")\n        final_valid_predictions.update(dict(zip(valid_ids, preds_valid_class)))\n\n#         fold_score = metrics.cohen_kappa_score(yvalid,  preds_valid_class, weights = \"quadratic\")\n#         fold_score = metrics.roc_auc_score(yvalid.values, preds_valid)  # Validation Set Score\n#         show_classification_scores(yvalid.values, preds_valid_class)\n        fold_score = metrics.mean_absolute_error(\n            yvalid, preds_valid\n        )  # Validation Set Score\n#         fold_score = metrics.mean_squared_error(yvalid, preds_valid, squared=False)\n        fold_scores.append(fold_score)\n\n        # Feature importance\n        fi = pd.DataFrame(\n            index=FEATURES,\n            data=model.feature_importances_,\n            columns=[f\"{fold}_importance\"],\n        )\n        feature_importance_lst.append(fi)\n\n        run_time = time.time() - start_time\n\n        print(f\"fold: {fold+1}, Score: {fold_score}, Run Time: {run_time:.2f}\")\n\n    return (\n        model,\n        feature_importance_lst,\n        fold_scores,\n        final_valid_predictions,\n        final_test_predictions,\n    )        ","metadata":{"papermill":{"duration":0.039719,"end_time":"2023-02-20T21:54:29.522426","exception":false,"start_time":"2023-02-20T21:54:29.482707","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:57:03.053682Z","iopub.execute_input":"2023-03-04T00:57:03.05433Z","iopub.status.idle":"2023-03-04T00:57:03.077943Z","shell.execute_reply.started":"2023-03-04T00:57:03.054293Z","shell.execute_reply":"2023-03-04T00:57:03.076929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_linear_model(model_dict, model_name:str, features:List[str], oof:pd.DataFrame) -> (float, float, pd.DataFrame):\n    (\n        model,\n        feature_importance_lst,\n        fold_scores,\n        final_valid_predictions,\n        final_test_predictions,\n    ) = train_cv_model(\n        train,\n        test,\n        model_dict[model_name],\n        features,\n        TARGET,\n        False, #Config.calc_probability,\n        ID,\n        {},\n        Config.N_FOLDS,\n        Config.seed,\n    )\n\n    cv_score, std_dev = show_fold_scores(fold_scores)\n\n    oof = save_oof_predictions(model_name, final_valid_predictions, oof)\n    oof.head()\n    save_test_predictions(model_name, final_test_predictions, sample_submission, TARGET)\n\n    return cv_score, std_dev, oof\n\n\ndef run_tree_model(model_dict, model_name:str, features:List[str], params, oof:pd.DataFrame) -> (float, float, pd.DataFrame):\n    (\n        model,\n        feature_importance_lst,\n        fold_scores,\n        final_valid_predictions,\n        final_test_predictions,\n    ) = train_xgb_model(\n        train,\n        test,\n        model_dict[model_name],\n        features,\n        TARGET,\n        Config.calc_probability,\n        ID,\n        params,\n        Config.N_FOLDS,\n        Config.seed,\n    )\n\n    cv_score, std_dev = show_fold_scores(fold_scores)\n    show_tree_model_fi(model, features)\n\n    oof = save_oof_predictions(model_name, final_valid_predictions, oof)\n    oof.head()\n    save_test_predictions(model_name, final_test_predictions, sample_submission, TARGET)\n\n    return cv_score, std_dev, oof","metadata":{"papermill":{"duration":0.029174,"end_time":"2023-02-20T21:54:29.567799","exception":false,"start_time":"2023-02-20T21:54:29.538625","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:57:03.081059Z","iopub.execute_input":"2023-03-04T00:57:03.082055Z","iopub.status.idle":"2023-03-04T00:57:03.092666Z","shell.execute_reply.started":"2023-03-04T00:57:03.08202Z","shell.execute_reply":"2023-03-04T00:57:03.091949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndef run_models4features(model_dict, model_lst:List[str], target:str, feature_lst:List[str], all_cv_scores:pd.DataFrame, linear_models:bool=True) -> pd.DataFrame:\n\n    oof = train[[ID, target, \"fold\"]].copy().reset_index(drop=True).copy()\n    oof.set_index(ID, inplace=True)\n\n    for idx, m in enumerate(model_lst):\n        model = model_lst[idx]\n        start_time = time.time()\n\n        print(f\"Model={model}\")\n\n        params = {}\n        if linear_models:\n                cv_score, std_dev, oof = run_linear_model(model_dict, model, feature_lst, oof)\n\n        else:\n            cv_score, std_dev, oof = run_tree_model(model_dict, model, feature_lst, params, oof)\n\n        run_time = time.time() - start_time\n\n        score_dict = {\"Model\": model, \"Score\": cv_score, \"StdDev\": std_dev, \"RunTime\": run_time}\n        all_cv_scores = all_cv_scores.append(score_dict, ignore_index=True)\n        print(f\"Model Run Time: {run_time:.2f}\")\n\n    return all_cv_scores\n\n\n","metadata":{"papermill":{"duration":0.028058,"end_time":"2023-02-20T21:54:29.61215","exception":false,"start_time":"2023-02-20T21:54:29.584092","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:57:03.093745Z","iopub.execute_input":"2023-03-04T00:57:03.094691Z","iopub.status.idle":"2023-03-04T00:57:03.110811Z","shell.execute_reply.started":"2023-03-04T00:57:03.094657Z","shell.execute_reply":"2023-03-04T00:57:03.109814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lgbm_params = {'n_estimators': Config.N_ESTIMATORS,\n                 'num_rounds': 404,\n                 'learning_rate': 0.19,\n                 'num_leaves': 17,\n                 'max_depth': 8,\n                 'min_data_in_leaf': 36,\n                 'lambda_l1': 0.96,\n                 'lambda_l2': 0.01,\n                 'min_gain_to_split': 11.32,\n                 'bagging_fraction': 0.6,\n                 'feature_fraction': 0.9}\n\n\nlgbm_params3 = {\n    \"n_estimators\": Config.N_ESTIMATORS,\n    'max_depth': 9,\n    'learning_rate': 0.01,\n    'min_data_in_leaf': 36, \n    'num_leaves': 100, \n    'feature_fraction': 0.8, \n    'bagging_fraction': 0.89, \n    'bagging_freq': 5, \n    'lambda_l2': 28,\n    \n    'seed': Config.seed,\n    'objective': 'regression',\n#     'boosting_type': 'gbdt',\n#     'device': 'gpu', \n#     'gpu_platform_id': 0,\n#     'gpu_device_id': 0,\n    'n_jobs': -1,\n    'metric': 'rmse',\n    'verbose': -1\n}\n    \nlgbm_params = gpu_ify_lgbm(lgbm_params)","metadata":{"papermill":{"duration":0.024677,"end_time":"2023-02-20T21:54:29.653861","exception":false,"start_time":"2023-02-20T21:54:29.629184","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:57:03.112982Z","iopub.execute_input":"2023-03-04T00:57:03.113654Z","iopub.status.idle":"2023-03-04T00:57:03.126591Z","shell.execute_reply.started":"2023-03-04T00:57:03.11362Z","shell.execute_reply":"2023-03-04T00:57:03.125728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_params = {\n    \"n_estimators\": Config.N_ESTIMATORS,  # 10_000,\n    \"max_depth\": 10,  # 10\n    \"objective\": \"reg:squarederror\", # Normal dist\n#     \"objective\": \"reg:gamma\", # Gamma dist\n    #     \"enable_categorical\": True,  # Only works with gpu_hist\n    #     \"eval_metric\": \"mae\",\n    #     \"metric\": \"mae\",\n    #     \"enable_categorical\": True,\n    \"n_jobs\": 8,  # 4\n    \"seed\": Config.seed,\n    \"tree_method\": \"hist\",\n    #         \"gpu_id\": 0,\n    \"subsample\": 0.9,  # 0.7\n    \"colsample_bytree\": 0.7,\n    \"use_label_encoder\": False,\n    \"learning_rate\": 0.05,  # 0.01\n}\n\nxgb_params3 = {\n    'n_estimators': Config.N_ESTIMATORS,\n    'learning_rate': 0.05,\n    'max_depth': 10,\n    'subsample': 0.8,\n    'colsample_bytree': 0.8,\n    'objective': 'reg:squarederror'\n}\n\nxgb_params_gamma = {\n    \"n_estimators\": Config.N_ESTIMATORS,  # 10_000,\n    \"max_depth\": 10,  # 10\n    \"objective\": \"reg:gamma\", # \"reg:gamma\", \"reg:squarederror\"\n    #     \"enable_categorical\": True,  # Only works with gpu_hist\n    #     \"eval_metric\": \"mae\",\n    #     \"metric\": \"mae\",\n    #     \"enable_categorical\": True,\n    \"n_jobs\": 8,  # 4\n    \"seed\": Config.seed,\n    \"tree_method\": \"hist\",\n    #         \"gpu_id\": 0,\n    \"subsample\": 0.9,  # 0.7\n    \"colsample_bytree\": 0.7,\n    \"use_label_encoder\": False,\n    \"learning_rate\": 0.05,  # 0.01\n}\n\nxgb_params_gpu1 = {'objective': 'reg:squarederror',\n              'booster': 'gbtree',\n              'eval_metric': 'rmse',\n              'n_estimators': 50000,\n              'learning_rate': 0.1,\n              'max_depth': 8,\n              'colsample_bytree': 0.4,\n              'subsample': 0.6,\n              'alpha': 8,\n              'lambda': 2,\n              'random_state': Config.seed,\n              'tree_method': 'gpu_hist'\n              }\n\nif Config.gpu:\n    xgb_params[\"tree_method\"] = \"gpu_hist\"\nelse:\n    xgb_params[\"tree_method\"] = \"hist\"","metadata":{"papermill":{"duration":0.025355,"end_time":"2023-02-20T21:54:29.695918","exception":false,"start_time":"2023-02-20T21:54:29.670563","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:57:03.128067Z","iopub.execute_input":"2023-03-04T00:57:03.128457Z","iopub.status.idle":"2023-03-04T00:57:03.138313Z","shell.execute_reply.started":"2023-03-04T00:57:03.128425Z","shell.execute_reply":"2023-03-04T00:57:03.137382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb_params = {\n    #     \"learning_rate\": 0.3277295792305584,\n    \"learning_rate\": 0.05,\n    \"l2_leaf_reg\": 3.1572972266001518,\n    \"bagging_temperature\": 0.6799604234141348,\n    \"random_strength\": 1.99590400593318,\n    \"depth\": 10,\n    \"min_data_in_leaf\": 93,\n    # \"iterations\": 100,  # 10000\n    \"n_estimators\": Config.N_ESTIMATORS,  # 10000\n    \"use_best_model\": True,\n    #     \"task_type\": \"GPU\",\n    \"random_seed\": Config.seed,\n}\n\ncb_params = gpu_ify_cb(cb_params)","metadata":{"papermill":{"duration":0.025264,"end_time":"2023-02-20T21:54:29.737527","exception":false,"start_time":"2023-02-20T21:54:29.712263","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:57:03.139828Z","iopub.execute_input":"2023-03-04T00:57:03.140174Z","iopub.status.idle":"2023-03-04T00:57:03.153763Z","shell.execute_reply.started":"2023-03-04T00:57:03.140141Z","shell.execute_reply":"2023-03-04T00:57:03.152834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_estimator_dict = {\n    \"xgb2\": xgb.XGBRegressor(**xgb_params),\n    \"xgb_best_params\": xgb.XGBRegressor(**best_xgb_params),\n    \"xgb3\": xgb.XGBRegressor(**xgb_params3),\n    \"xgb_params_gamma\": xgb.XGBRegressor(**xgb_params_gamma),\n    \"xgb_params_gpu1\": xgb.XGBRegressor(**xgb_params_gpu1),\n    \n    \n    \"lgbm1\": lgb.LGBMRegressor(**lgbm_params),\n\n    \"cat1\": cb.CatBoostRegressor(),\n    \"cat2\": cb.CatBoostRegressor(**cb_params),\n    \"cat_best_params\": cb.CatBoostRegressor(**best_cb_params),\n\n    \"xgb1\": xgb.XGBRegressor(),\n    \"lgbm0\": lgb.LGBMRegressor(),\n    \"lgbm3\": lgb.LGBMRegressor(lgbm_params3),\n    \"lgbm2\": lgb.LGBMRegressor(\n        learning_rate=0.05,\n        max_depth=15,\n        num_leaves=11,\n        feature_fraction=0.3,\n        subsample=0.1,\n        n_jobs=-1,\n    ),\n    \"lgbm3\": lgb.LGBMRegressor(**lgbm_params),\n    \"lgbm_best_params\": lgb.LGBMRegressor(**best_lgbm_params),\n\n\n    \"lin_reg\": linear_model.LinearRegression(),\n    \"lasso\": linear_model.Lasso(),\n    \"ridge\": linear_model.Ridge(max_iter=7000),\n    \"ridge_25\": linear_model.Ridge(fit_intercept=True, solver='auto', alpha=0.25, max_iter=7000),\n    \"ridge_50\": linear_model.Ridge(fit_intercept=True, solver='auto', alpha=0.5, max_iter=7000),\n}","metadata":{"papermill":{"duration":0.029521,"end_time":"2023-02-20T21:54:29.826037","exception":false,"start_time":"2023-02-20T21:54:29.796516","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:57:03.155477Z","iopub.execute_input":"2023-03-04T00:57:03.155925Z","iopub.status.idle":"2023-03-04T00:57:03.167584Z","shell.execute_reply.started":"2023-03-04T00:57:03.155875Z","shell.execute_reply":"2023-03-04T00:57:03.166645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tree Models","metadata":{"papermill":{"duration":0.016131,"end_time":"2023-02-20T21:54:29.858504","exception":false,"start_time":"2023-02-20T21:54:29.842373","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\n\n# model_lst = [\"xgb3\",\"xgb_best_params\", \"lgbm_best_params\", \"cat_best_params\", \"xgb1\", \"xgb2\", \"lgbm1\", \"lgbm2\", \"cat1\", \"cat2\"]\n# model_lst = [\"xgb_params_gpu1\",\"xgb_best_params\", \"lgbm_best_params\", \"cat_best_params\", \"xgb_params_gamma\", \"xgb3\", \"xgb1\", \"xgb2\", \"lgbm0\", \"lgbm1\", \"lgbm2\", \"lgbm3\", \"cat1\", \"cat2\"]\nmodel_lst = [\"xgb3\", \"xgb1\", \"xgb2\", \"lgbm0\", \"lgbm1\", \"lgbm2\", \"lgbm3\", \"cat1\", \"cat2\"]\n# model_lst = = []\nall_cv_scores = run_models4features(model_estimator_dict, model_lst, TARGET, FEATURES, all_cv_scores, linear_models=False)    \n\nall_cv_scores.sort_values(by=[\"Score\"], ascending=False)","metadata":{"papermill":{"duration":1674.045619,"end_time":"2023-02-20T22:22:23.920698","exception":false,"start_time":"2023-02-20T21:54:29.875079","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-03-04T00:57:03.169006Z","iopub.execute_input":"2023-03-04T00:57:03.169473Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Linear Models","metadata":{"papermill":{"duration":0.028809,"end_time":"2023-02-20T22:22:23.981981","exception":false,"start_time":"2023-02-20T22:22:23.953172","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_lst = [\"lin_reg\", \"lasso\", \"ridge\", \"ridge_25\", \"ridge_50\"]\nmodel_lst = [\"lasso\", \"ridge\",  \"ridge_50\"]\n# model_lst = []\n# all_cv_scores = run_models4features(model_lst, TARGET, FEATURES, all_cv_scores, linear_models=True)    \nall_cv_scores = run_models4features(model_estimator_dict, model_lst, TARGET, FEATURES, all_cv_scores, linear_models=True)    \n\nall_cv_scores.head()","metadata":{"papermill":{"duration":2.423701,"end_time":"2023-02-20T22:22:26.434266","exception":false,"start_time":"2023-02-20T22:22:24.010565","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission.head(20)","metadata":{"papermill":{"duration":0.054019,"end_time":"2023-02-20T22:22:26.511612","exception":false,"start_time":"2023-02-20T22:22:26.457593","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(177, 156, 217, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">Blend Models</h1>\n</div>","metadata":{"papermill":{"duration":0.022948,"end_time":"2023-02-20T22:22:26.557802","exception":false,"start_time":"2023-02-20T22:22:26.534854","status":"completed"},"tags":[]}},{"cell_type":"code","source":"all_blend_scores = pd.DataFrame(\n    {\n        \"Model\": pd.Series(dtype=\"str\"),\n        \"Score\": pd.Series(dtype=\"float\"),\n        \"StdDev\": pd.Series(dtype=\"float\"),\n    }\n)","metadata":{"papermill":{"duration":0.032337,"end_time":"2023-02-20T22:22:26.613362","exception":false,"start_time":"2023-02-20T22:22:26.581025","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_lst","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_lst = [\"xgb_params_gpu1\", \"xgb_best_params\",\"xgb1\", \"xgb2\",\"xgb3\", \"cat1\", \"cat_best_params\",\"lgbm0\", \"lgbm1\", \"lgbm3\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(model_lst)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_names = [f\"target_{model}\" for model in model_lst]\ntarget_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission[TARGET] = sample_submission[target_names].sum(axis=1) / len(model_lst)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission[[ID, TARGET]].to_csv(\"submission_models_wt_avg.csv\", index=False)\nsample_submission[[ID, TARGET]].tail(8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission[TARGET] = (\n#     (sample_submission[\"target_xgb_bp\"] * 2 )\n#     + (sample_submission[\"target_lgbm_bp\"]  )\n    (sample_submission[\"target_xgb1\"] * 3 )\n    + (sample_submission[\"target_lgbm1\"])\n#     + (sample_submission[\"target_lgbm2\"])    \n#     + (sample_submission[\"target_lgbm2\"])\n    + (sample_submission[\"target_cat1\"] )\n    + (sample_submission[\"target_cat2\"] )    \n#     + (sample_submission[\"target_cat_bp\"] )\n#     + (sample_submission[\"target_svc\"] )\n#     + (sample_submission[\"target_log_reg3\"] )\n#     + (sample_submission[\"target_cat2\"] )\n)/6\n\n# sample_submission[TARGET] = sample_submission[TARGET].astype(int)","metadata":{"papermill":{"duration":0.033943,"end_time":"2023-02-20T22:22:26.670445","exception":false,"start_time":"2023-02-20T22:22:26.636502","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission[[ID, TARGET]].to_csv(\"submission_wt_avg.csv\", index=False)\nsample_submission[[ID, TARGET]].tail(8)","metadata":{"papermill":{"duration":0.066044,"end_time":"2023-02-20T22:22:26.75964","exception":false,"start_time":"2023-02-20T22:22:26.693596","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_cv_scores.sort_values(by=[\"Score\"], ascending=False)","metadata":{"papermill":{"duration":0.039234,"end_time":"2023-02-20T22:22:26.823244","exception":false,"start_time":"2023-02-20T22:22:26.78401","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(177, 156, 217, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">Level 1 Stack Models</h1>\n</div>","metadata":{"execution":{"iopub.execute_input":"2023-02-18T22:51:38.505536Z","iopub.status.busy":"2023-02-18T22:51:38.505173Z","iopub.status.idle":"2023-02-18T22:51:38.513105Z","shell.execute_reply":"2023-02-18T22:51:38.511507Z","shell.execute_reply.started":"2023-02-18T22:51:38.5055Z"},"papermill":{"duration":0.023396,"end_time":"2023-02-20T22:22:26.870612","exception":false,"start_time":"2023-02-20T22:22:26.847216","status":"completed"},"tags":[]}},{"cell_type":"code","source":"## TODO: Generate these dictionaries from model names\n\ntrain_oof_dict = {\n    \"train_pred_cat1\": \"train_pred_cat1.csv\",\n    \"train_pred_cat2\": \"train_pred_cat2.csv\",\n    \"train_pred_lgbm1\": \"train_pred_lgbm1.csv\",    \n    \"train_pred_lgbm2\": \"train_pred_lgbm2.csv\",    \n    \"train_pred_xgb1\": \"train_pred_xgb1.csv\"\n}\n\ntest_pred_dict = {\n    \"submission_cat1\": \"submission_cat1.csv\",\n    \"submission_cat2\": \"submission_cat2.csv\",\n    \"submission_lgbm1\": \"submission_lgbm1.csv\",\n    \"submission_lgbm2\": \"submission_lgbm2.csv\",\n    \"submission_xgb1\": \"submission_xgb1.csv\",\n}","metadata":{"papermill":{"duration":0.032214,"end_time":"2023-02-20T22:22:26.926265","exception":false,"start_time":"2023-02-20T22:22:26.894051","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def blend_results(train_oof_dict, test_pred_dict):\n    oof_df = pd.DataFrame()\n    test_preds_df = pd.DataFrame()\n\n    for name, train_oof_fname in train_oof_dict.items():\n        fname = \"../working/\" + train_oof_fname\n        print(f\"Processing {name}, {train_oof_fname}\")\n        df = pd.read_csv(fname)\n        print(df.head())\n#         print(df.iloc[:,1])\n        preds = pd.Series(df.iloc[:,1], name=name)\n#         print(preds[:5])\n        oof_df = pd.concat([oof_df, preds], axis=1)\n    #     oof_df = pd.concat([oof_df, pd.Series(np.load(TRAIN_PATH / train_oof), name=name)], axis=1)\n\n    for name, test_pred_fname in test_pred_dict.items():\n        fname = \"../working/\" + test_pred_fname\n        print(f\"{name}, {test_pred_fname}\")\n        df = pd.read_csv(fname)\n        print(df.head())\n        preds = pd.Series(df.iloc[:,1], name=name)\n        test_preds_df = pd.concat([test_preds_df, preds], axis=1)\n\n    print(\"=== oof ===\")\n    print(oof_df.head())\n    print(\"=== test_preds ===\")\n    print(test_preds_df.head())\n    return oof_df, test_preds_df\n    \n# (oof_df, preds_df) = blend_results(train_oof_dict, test_pred_dict)    ","metadata":{"papermill":{"duration":0.035437,"end_time":"2023-02-20T22:22:26.985122","exception":false,"start_time":"2023-02-20T22:22:26.949685","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_oof_results(train_oof_dict, test_pred_dict):\n    oof_df = pd.DataFrame()\n    test_preds_df = pd.DataFrame()\n\n    for name, train_oof_fname in train_oof_dict.items():\n        fname = \"../working/\" + train_oof_fname\n        print(f\"Processing {name}, {train_oof_fname}\")\n        df = pd.read_csv(fname)\n        print(df.head())\n#         print(df.iloc[:,1])\n        preds = pd.Series(df.iloc[:,1], name=name)\n#         print(preds[:5])\n        oof_df = pd.concat([oof_df, preds], axis=1)\n    #     oof_df = pd.concat([oof_df, pd.Series(np.load(TRAIN_PATH / train_oof), name=name)], axis=1)\n\n    for name, test_pred_fname in test_pred_dict.items():\n        fname = \"../working/\" + test_pred_fname\n        print(f\"{name}, {test_pred_fname}\")\n        df = pd.read_csv(fname)\n        print(df.head())\n        preds = pd.Series(df.iloc[:,1], name=name)\n        test_preds_df = pd.concat([test_preds_df, preds], axis=1)\n\n    print(\"=== oof ===\")\n    print(oof_df.head())\n    print(\"=== test_preds ===\")\n    print(test_preds_df.head())\n    return oof_df, test_preds_df\n    \n(oof_df, preds_df) = load_oof_results(train_oof_dict, test_pred_dict) ","metadata":{"papermill":{"duration":0.163528,"end_time":"2023-02-20T22:22:27.172529","exception":false,"start_time":"2023-02-20T22:22:27.009001","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_df.head()","metadata":{"papermill":{"duration":0.039405,"end_time":"2023-02-20T22:22:27.236263","exception":false,"start_time":"2023-02-20T22:22:27.196858","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_df.head()","metadata":{"papermill":{"duration":0.03811,"end_time":"2023-02-20T22:22:27.298259","exception":false,"start_time":"2023-02-20T22:22:27.260149","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(preds_df)","metadata":{"papermill":{"duration":0.033006,"end_time":"2023-02-20T22:22:27.355749","exception":false,"start_time":"2023-02-20T22:22:27.322743","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_lr(useful_features:List[str], TARGET:str, train_df:pd.DataFrame, test_df:pd.DataFrame) -> (List[float],List[float]):\n    final_predictions = []\n    scores = []\n\n    kfold = model_selection.KFold(n_splits=Config.N_FOLDS, shuffle=True, random_state=Config.seed)\n\n    for fold, (train_idx, valid_idx) in enumerate(kfold.split(train_df)):\n        xtrain = train_df.iloc[train_idx].reset_index(drop=True)\n        xvalid = train_df.iloc[valid_idx].reset_index(drop=True)\n\n        xtest = test_df[useful_features].copy()\n\n        ytrain = xtrain[TARGET]\n        yvalid = xvalid[TARGET]\n\n        xtrain = xtrain[useful_features]\n        xvalid = xvalid[useful_features]\n\n#         model = LogisticRegression()\n        model = linear_model.LinearRegression()\n        # Smaller C means more regularization; default=1.0\n        # 2947.0517025518097\n#         model = LogisticRegression(max_iter=500, C=2947.0517025518097, penalty='l2',solver='newton-cg')\n#         model = LogisticRegression(C = 2947.0517025518097,\n#                         max_iter = 500,\n#                         penalty = 'l2',\n#                         solver = 'liblinear')\n        model.fit(xtrain, ytrain)\n\n        preds_valid = model.predict_proba(xvalid)[:,-1]\n        test_preds = model.predict_proba(xtest)[:,-1]\n\n        final_predictions.append(test_preds)\n#         score = metrics.roc_auc_score(yvalid, preds_valid)\n        score = metrics.mean_squared_error(yvalid, preds_valid, squared=False)\n        print(f\"Fold={fold}, Score={score}\")\n        scores.append(score)\n    return scores, final_predictions\n","metadata":{"papermill":{"duration":0.036473,"end_time":"2023-02-20T22:22:27.416319","exception":false,"start_time":"2023-02-20T22:22:27.379846","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# useful_features = [\"pred_lda\", \"pred_gbc\",\"pred_gbc2\", \"pred_cat_bp\", \"pred_cat1\", \"pred_lgbm1\", \"pred_lgbm2\", \"pred_lgbm_bp\", \"pred_xgb1\", \"pred_xgb_bp\"]\nuseful_features = [ \"train_pred_cat1\", \"train_pred_cat2\", \"train_pred_lgbm1\", \"train_pred_lgbm2\", \"train_pred_xgb1\"]","metadata":{"papermill":{"duration":0.031608,"end_time":"2023-02-20T22:22:27.472067","exception":false,"start_time":"2023-02-20T22:22:27.440459","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_df[useful_features].head()","metadata":{"papermill":{"duration":0.041269,"end_time":"2023-02-20T22:22:27.537879","exception":false,"start_time":"2023-02-20T22:22:27.49661","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds_df[useful_features].head()","metadata":{"papermill":{"duration":0.031268,"end_time":"2023-02-20T22:22:27.594469","exception":false,"start_time":"2023-02-20T22:22:27.563201","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fold_scores, final_predictions = run_lr(useful_features, TARGET, oof_df, preds_df)\n# test_preds = np.mean(np.column_stack(final_predictions), axis=1)\n# cv_score, std_dev = show_fold_scores(fold_scores)\n# create_submission(\"level1_lr\", TARGET, test_preds)","metadata":{"papermill":{"duration":0.031201,"end_time":"2023-02-20T22:22:27.650507","exception":false,"start_time":"2023-02-20T22:22:27.619306","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.max_colwidth = 100\npd.set_option(\"display.max_rows\", 999)\npd.set_option(\"display.precision\", 5)\npd.options.display.float_format = '{:.2f}'.format\npd.options.display.max_colwidth","metadata":{"papermill":{"duration":0.034004,"end_time":"2023-02-20T22:22:27.709196","exception":false,"start_time":"2023-02-20T22:22:27.675192","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_cv_scores.sort_values(by=[\"Score\"], ascending=False)","metadata":{"papermill":{"duration":0.039339,"end_time":"2023-02-20T22:22:27.773217","exception":false,"start_time":"2023-02-20T22:22:27.733878","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}